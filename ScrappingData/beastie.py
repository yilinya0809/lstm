# -*- coding: utf-8 -*-
"""Crawling_Beastie.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16UMVKh8qKavjUYLU2iQuSZMWC1FaTU6j
"""

from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities

import time

### Crawling Setup
browser = webdriver.Chrome(executable_path='./chromedriver')
browser.implicitly_wait(3)

##비스티보이즈 2014

url='https://tickets.interpark.com/goods/14006159'
browser.get(url)

## 관람후기 클릭 시뮬레이션

browser.find_element_by_xpath('//*[@id="productMainBody"]/nav/div/div/ul/li[3]/a').click()

import pandas as pd


reviews = []
score = []


for page in range(1,50):
    if page == 1:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                         score.append(1)
                    else:
                         score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a').click()
    
    else:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a[2]').click()

for page in range(8,50):
    for i in range(1,11):
        if i == 1:
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
        
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
                
                
        else:
            browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
            time.sleep(0.1)
    
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
    
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
    browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a[2]').click()

for page in range(19,50):
    for i in range(1,11):
        if i == 1:
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
        
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
                
                
        else:
            browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
            time.sleep(0.1)
    
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
    
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
    browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a[2]').click()

df=pd.DataFrame({'Reviews': reviews, 'Score':score})
df.to_csv('Beastieboys2014.csv', encoding = "utf-8-sig")

##비스티 2016

url='https://tickets.interpark.com/goods/16006425'
browser.get(url)

## 관람후기 클릭 시뮬레이션

browser.find_element_by_xpath('//*[@id="productMainBody"]/nav/div/div/ul/li[3]/a').click()

import pandas as pd


reviews = []
score = []


for page in range(1,14):
    if page == 1:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                         score.append(1)
                    else:
                         score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a').click()
    
    else:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a[2]').click()

for page in range(8,14):
    for i in range(1,11):
        if i == 1:
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
        
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
                
                
        else:
            browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
            time.sleep(0.1)
    
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
    
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
    browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a[2]').click()

for page in range(12,14):
    for i in range(1,11):
        if i == 1:
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
        
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
                
                
        else:
            browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
            time.sleep(0.1)
    
            html = browser.page_source
            soup = BeautifulSoup(html, 'html.parser')
    
            for j in range(15):
                reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                    score.append(1)
                else:
                    score.append(0)
    browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a[2]').click()

df2=pd.DataFrame({'Reviews': reviews, 'Score':score})
df2.to_csv('Beastie2016.csv', encoding = "utf-8-sig")

##비스티 2017

url='https://tickets.interpark.com/goods/17000454'
browser.get(url)

## 관람후기 클릭 시뮬레이션

browser.find_element_by_xpath('//*[@id="productMainBody"]/nav/div/div/ul/li[3]/a').click()

import pandas as pd


reviews = []
score = []


for page in range(1,44):
    if page == 1:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                         score.append(1)
                    else:
                         score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a').click()
    
    else:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

df3=pd.DataFrame({'Reviews': reviews, 'Score':score})
df3.to_csv('Beastie2017.csv', encoding = "utf-8-sig")

##비스티 2020

url='https://tickets.interpark.com/goods/20005886'
browser.get(url)

## 관람후기 클릭 시뮬레이션

browser.find_element_by_xpath('//*[@id="productMainBody"]/nav/div/div/ul/li[4]/a').click()

import pandas as pd


reviews = []
score = []


for page in range(1,83):
    if page == 1:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                         score.append(1)
                    else:
                         score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a').click()
    
    else:
        for i in range(1,11):
            if i == 1:
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
        
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())        
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
                
                
            else:
                browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/ol/li['+ str(i) +']/a').click()
                time.sleep(0.1)
    
                html = browser.page_source
                soup = BeautifulSoup(html, 'html.parser')
    
                for j in range(15):
                    reviews.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text() + ' ' + soup.find_all("p", {"class": "bbsText"})[j].get_text())
                    if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                        score.append(1)
                    else:
                        score.append(0)
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[3]/div[2]/a[2]').click()

df4=pd.DataFrame({'Reviews': reviews, 'Score':score})
df4.to_csv('Beastie2020.csv', encoding = "utf-8-sig")

