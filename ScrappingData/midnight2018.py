# -*- coding: utf-8 -*-
"""Crawling_Midnight2018-Copy1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FEhEI88yBRVcYS-E6LwXal9sppDnJDZh
"""

from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities

import time

### Crawling Setup
browser = webdriver.Chrome(executable_path='./chromedriver')
browser.implicitly_wait(3)

## 니진스키 후기(웹)

url='https://tickets.interpark.com/goods/19005443'
browser.get(url)

## 관람후기 클릭 시뮬레이션

browser.find_element_by_xpath('//*[@id="productMainBody"]/nav/div/div/ul/li[4]/a').click()

## 관람후기 1 페이지 긁어오기
import pandas as pd


titles = []
reviews = []
score = []

html = browser.page_source
soup = BeautifulSoup(html, 'html.parser')

review_title_1 = soup.find_all("strong", {"class": "bbsTitleText"})
review_1 = soup.find_all("p", {"class": "bbsText"})
ratings_1 = soup.select('div.prdStarScore > span.blind')

for i in range(len(review_title_1)):
    titles.append(review_title_1[i].get_text())
    reviews.append(review_1[i].get_text())
    
    if ratings_1[i+2].get_text() == "평점: 강력 추천":
        score.append(1)
    else:
        score.append(0)

## 2-10 페이지 긁어오기

for i in range(2,11):
    browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
    time.sleep(0.1)
    
    html = browser.page_source
    soup = BeautifulSoup(html, 'html.parser')
    
    for j in range(15):
        titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
        reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
        if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
            score.append(1)
        else:
            score.append(0)

print(len(titles),len(reviews),len(score))

pd.DataFrame({'Title': titles, 'Text': reviews, 'Score':score})

##11페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(5)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##21페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##31페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##41페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##51페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##61페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##71페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##81페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##91페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

#101페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##91페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##91페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##91페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##91페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##91페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

##91페이지 클릭

browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/a[2]').click()

for i in range(1,11):
    if i == 1:
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)
                
                
    else:
        browser.find_element_by_xpath('//*[@id="prdReview"]/div/div[4]/div[2]/ol/li['+ str(i) +']/a').click()
        time.sleep(0.1)
    
        html = browser.page_source
        soup = BeautifulSoup(html, 'html.parser')
    
        for j in range(15):
            titles.append(soup.find_all("strong", {"class": "bbsTitleText"})[j].get_text())
            reviews.append(soup.find_all("p", {"class": "bbsText"})[j].get_text())
        
            if soup.select('div.prdStarScore > span.blind')[j+2].get_text() == "평점: 강력 추천":
                score.append(1)
            else:
                score.append(0)

df=pd.DataFrame({'Title': titles, 'Text': reviews, 'Score':score})
df.to_csv('Midnight2018.csv', encoding = "utf-8-sig")

